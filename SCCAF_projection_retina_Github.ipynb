{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb504db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from SCCAF import *\n",
    "import os\n",
    "os.chdir(\"./RETINA/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sele_dataset(adTr, adLn, n_HVG = 2000, Ln_species = 'Patch', Tr_species = 'TenX'):\n",
    "#generate new dataset with HVG only\n",
    "#input adTr: trainging set, full dataset; adLn:testing set, full dataset; n_HVG, number of HVG\n",
    "# merker_gene: use only marker gene\n",
    "#output Tr_sub, Ln_sub: splited Training and testing dataset, with combine calculated PCA\n",
    "   \n",
    "    \n",
    "    adTr.X = adTr.layers['raw']\n",
    "    #sc.pp.scale(adTr)\n",
    "    \n",
    "    adLn.X = adLn.layers['raw']\n",
    "    #sc.pp.scale(adLn)\n",
    "    \n",
    "    if scipy.sparse.issparse(adTr.X):\n",
    "        adTr_selected_gene = adTr.var_names[np.array(np.std(adTr.X.todense(), axis=0).argsort())[0][-n_HVG:][::-1]]\n",
    "    else:\n",
    "        adTr_selected_gene = adTr.var_names[np.array(np.std(adTr.X, axis=0).argsort())[-n_HVG:][::-1]]\n",
    "    \n",
    "    \n",
    "    if scipy.sparse.issparse(adLn.X):\n",
    "        adLn_selected_gene = adLn.var_names[np.array(np.std(adLn.X.todense(), axis=0).argsort())[0][-n_HVG:][::-1]]\n",
    "    else:\n",
    "        adLn_selected_gene = adLn.var_names[np.array(np.std(adLn.X, axis=0).argsort())[-n_HVG:][::-1]]\n",
    "    \n",
    "    select_gene  = unique(list(adTr_selected_gene)+list(adLn_selected_gene))\n",
    "    \n",
    "    adTr_sele = adTr[:,select_gene]\n",
    "    adTr_sele.obs['source']= Tr_species\n",
    "    \n",
    "    adLn_sele = adLn[:,select_gene]\n",
    "    adLn_sele.obs['source']= Ln_species\n",
    "\n",
    "    TrLn = adTr_sele.concatenate(adLn_sele)\n",
    "    \n",
    "\n",
    "    #sc.pp.scale(TrLn)\n",
    "    #sc.tl.pca(TrLn)\n",
    "    #sc.pl.pca(TrLn, color = ['marker1','source'])\n",
    "    \n",
    "    #Tr_sub = TrLn[TrLn.obs['source']==Tr_source,:]\n",
    "    #Ln_sub = TrLn[TrLn.obs['source']==Ln_source,:]\n",
    "     \n",
    "    return TrLn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PCA_Harmony(TrLn, run_Harmony = True, theta = 5,rep = 1,key = 'org_cluster' ):\n",
    "#run PCA and Harmony (optional) \n",
    "#input TrLn, combined dataset from Training set and testing set, generated by function sele_dataset\n",
    "#output Tr_sub, Ln_sub: splited Training and testing dataset, with combine calculated PCA and Harmony, in layer obsm\n",
    "    \n",
    "    #TrLn.X = TrLn.layers['raw']\n",
    "    if scipy.sparse.issparse(TrLn.X): \n",
    "        X = TrLn.X.todense().T\n",
    "    else:\n",
    "        X = TrLn.T\n",
    "    #TrLn.obsm['X_pca'] = sc.tl.pca(np.array(scale(X.T)), n_comps=100)\n",
    "    #sc.pp.scale(TrLn)\n",
    "    sc.tl.pca(TrLn)\n",
    "    #sc.pl.pca(TrLn, color = [key,'source'])\n",
    "    \n",
    "    #Tr_sub = TrLn[TrLn.obs['source']==Tr_source,:]\n",
    "    #Ln_sub = TrLn[TrLn.obs['source']==Ln_source,:]\n",
    "    \n",
    "    if run_Harmony:\n",
    "        \n",
    "        data_mat = TrLn.obsm['X_pca']\n",
    "        meta_data = TrLn.obs\n",
    "\n",
    "        TrLn.obsm['X_pca'].shape\n",
    "        #ho = hm.run_harmony(data_mat, meta_data, 'species')\n",
    "        ho = hm.run_harmony(data_mat, meta_data, 'source',theta = theta)\n",
    "        res = ho.Z_corr\n",
    "        print('Run Harmony')\n",
    "        TrLn.obsm['X_harmony'] = res.T\n",
    "        sc.pp.neighbors(TrLn)\n",
    "        #sc.tl.umap(TrLn)\n",
    "        #sc.tl.tsne(humk, n_jobs = 20)\n",
    "        #sc.pl.umap(TrLn, color = ['source',key])\n",
    "        #sc.pl.tsne(humk,color = ['species','marker1','marker2'])\n",
    "\n",
    "#         for i in range(1,rep):\n",
    "        \n",
    "#             print(\"this is the \" + str(i) + \" time of harmony\" )\n",
    "    \n",
    "#             data_mat = TrLn.obsm['X_harmony']\n",
    "#             meta_data = TrLn.obs\n",
    "\n",
    "#             #ho = hm.run_harmony(data_mat, meta_data, 'species')\n",
    "#             ho = hm.run_harmony(data_mat, meta_data, 'source', theta = 5)\n",
    "#             res = ho.Z_corr\n",
    "#             TrLn.obsm['X_harmony'] = res.T\n",
    "#             sc.pp.neighbors(TrLn,use_rep = 'X_harmony')\n",
    "#             print('Finished Harmony')\n",
    "#             #sc.tl.umap(TrLn)\n",
    "#             #sc.tl.tsne(humk, n_jobs = 20)\n",
    "#             #sc.pl.umap(TrLn, color = ['source',key])\n",
    "#             #sc.pl.tsne(humk,color = ['species','marker1','marker2'])\n",
    " \n",
    "    \n",
    "    return TrLn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f339b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_mean(df_prob_rep):\n",
    "#caluculating probability mean from the big repeat df\n",
    "#input: pd.Series each obj is a prob dataframe of each repeat\n",
    "#output: df with mean of each cell, each prob \n",
    "    cell_type_list = list(df_prob_rep[0].columns)\n",
    "    df_prob_mean = pd.DataFrame()\n",
    "    for cell_type in cell_type_list:\n",
    "        #print('calculating ' + cell_type + '...')\n",
    "        df_prob_type = pd.DataFrame()\n",
    "        for rep_ind in list(df_prob_rep.index):\n",
    "            #print(rep_ind)\n",
    "            df_prob_type_mean = pd.DataFrame()\n",
    "            df_prob_type[rep_ind]=df_prob_rep[rep_ind][cell_type]\n",
    "        df_prob_type_mean = mean(df_prob_type, axis = 1)\n",
    "        df_prob_mean[cell_type]=df_prob_type_mean\n",
    "    return df_prob_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_median(df_prob_rep):\n",
    "#caluculating probability median from the big repeat df\n",
    "#input: pd.Series each obj is a prob dataframe of each repeat\n",
    "#output: df with median of each cell, each prob \n",
    "    cell_type_list = list(df_prob_rep[0].columns)\n",
    "    df_prob_median = pd.DataFrame()\n",
    "    for cell_type in cell_type_list:\n",
    "        #print('calculating ' + cell_type + '...')\n",
    "        df_prob_type = pd.DataFrame()\n",
    "        for rep_ind in list(df_prob_rep.index):\n",
    "            #print(rep_ind)\n",
    "            df_prob_type_median = pd.DataFrame()\n",
    "            df_prob_type[rep_ind]=df_prob_rep[rep_ind][cell_type]\n",
    "        df_prob_type_median = median(df_prob_type, axis = 1)\n",
    "        df_prob_median[cell_type]=df_prob_type_median\n",
    "    return df_prob_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626865c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_max(df_prob_rep):\n",
    "#caluculating probability max from the big repeat df\n",
    "#input: pd.Series each obj is a prob dataframe of each repeat\n",
    "#output: df with max of each cell, each prob \n",
    "    cell_type_list = list(df_prob_rep[0].columns)\n",
    "    df_prob_max = pd.DataFrame()\n",
    "    for cell_type in cell_type_list:\n",
    "        #print('calculating ' + cell_type + '...')\n",
    "        df_prob_type = pd.DataFrame()\n",
    "        for rep_ind in list(df_prob_rep.index):\n",
    "            #print(rep_ind)\n",
    "            df_prob_type_max = pd.DataFrame()\n",
    "            df_prob_type[rep_ind]=df_prob_rep[rep_ind][cell_type]\n",
    "        df_prob_type_max = df_prob_type.max(axis = 1)\n",
    "        df_prob_max[cell_type]=df_prob_type_max\n",
    "    return df_prob_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ede622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_min(df_prob_rep):\n",
    "#caluculating probability min from the big repeat df\n",
    "#input: pd.Series each obj is a prob dataframe of each repeat\n",
    "#output: df with min of each cell, each prob \n",
    "    cell_type_list = list(df_prob_rep[0].columns)\n",
    "    df_prob_min = pd.DataFrame()\n",
    "    for cell_type in cell_type_list:\n",
    "        #print('calculating ' + cell_type + '...')\n",
    "        df_prob_type = pd.DataFrame()\n",
    "        for rep_ind in list(df_prob_rep.index):\n",
    "            #print(rep_ind)\n",
    "            df_prob_type_min = pd.DataFrame()\n",
    "            df_prob_type[rep_ind]=df_prob_rep[rep_ind][cell_type]\n",
    "        df_prob_type_min = df_prob_type.min(axis = 1)\n",
    "        df_prob_min[cell_type]=df_prob_type_min\n",
    "    return df_prob_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_subset(adTr,key = 'org_cluster', n=50, frac=1):\n",
    "#subsetting the datasets based on their cell types\n",
    "    X_train, X_test, y_train, y_test = train_test_split_per_type(adTr.X, adTr.obs[key], n=n, frac=frac)\n",
    "    adTr_sub = adTr[y_train.index,:]\n",
    "    return adTr_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_save_score(df_prob_rep, manual_label, param, savepath = 'data/retina_label/score_summary.csv'):\n",
    "#recored the score and write to csv\n",
    "#input df_prob_rep, repeating results\n",
    "#input manual_label: manual labeling results of each patched cells\n",
    "#input param, the parameter string indicating \n",
    "#outout, score results\n",
    "    f = open(f'data/retina_label/predict_results/{str(param)}.pckl', 'wb')\n",
    "    pickle.dump(df_prob_rep, f)\n",
    "    f.close()\n",
    "    \n",
    "    #get mean, median and min and max from each repeats\n",
    "    df_prob_median = pd.DataFrame()\n",
    "    df_prob_median = get_prob_median(df_prob_rep)\n",
    "    df_prob_median.index = df_prob_rep['rep_0'].index\n",
    "    \n",
    "    df_prob_mean = pd.DataFrame()\n",
    "    df_prob_mean = get_prob_mean(df_prob_rep)\n",
    "    df_prob_mean.index = df_prob_rep['rep_0'].index\n",
    "    \n",
    "    df_prob_max = pd.DataFrame()\n",
    "    df_prob_max = get_prob_max(df_prob_rep)\n",
    "    df_prob_max.index = df_prob_rep['rep_0'].index\n",
    "    \n",
    "    df_prob_min = pd.DataFrame()\n",
    "    df_prob_min = get_prob_min(df_prob_rep)\n",
    "    df_prob_min.index = df_prob_rep['rep_0'].index\n",
    "    \n",
    "    #find the suited cluster\n",
    "    pre_results = pd.DataFrame(index = df_prob_median.index)\n",
    "    pre_results['predict_cluster_median'] = df_prob_median.idxmax(axis=1)\n",
    "    pre_results['predict_cluster_medianprob'] = df_prob_median.max(axis=1)\n",
    "    \n",
    "    pre_results['predict_cluster_mean'] = df_prob_mean.idxmax(axis=1)\n",
    "    pre_results['predict_cluster_meanprob'] = df_prob_mean.max(axis=1)\n",
    "    \n",
    "    pre_results['predict_cluster_max'] = df_prob_max.idxmax(axis=1)\n",
    "    pre_results['predict_cluster_maxprob'] = df_prob_max.max(axis=1)\n",
    "    \n",
    "    pre_results['predict_cluster_min'] = df_prob_min.idxmin(axis=1)\n",
    "    pre_results['predict_cluster_minprob'] = df_prob_min.min(axis=1)\n",
    "    \n",
    "    # get each category\n",
    "    NotChange_list = manual_label[manual_label['allow_modification']=='N'].index.tolist()\n",
    "    MaybeChange_list = manual_label[manual_label['allow_modification']=='*'].index.tolist()\n",
    "    Change_list = manual_label[manual_label['allow_modification']=='Y'].index.tolist()\n",
    "    \n",
    "    #compare annotation\n",
    "    pre_results['conclusion'] = manual_label['conclusion']\n",
    "    pre_results['Match_median'] = pre_results['conclusion']== pre_results['predict_cluster_median']\n",
    "    pre_results['Match_mean'] = pre_results['conclusion']== pre_results['predict_cluster_mean']\n",
    "    pre_results['Match_max'] = pre_results['conclusion']== pre_results['predict_cluster_max']\n",
    "    pre_results['Match_min'] = pre_results['conclusion']== pre_results['predict_cluster_min']\n",
    "    \n",
    "    score_sum = pd.DataFrame()\n",
    "    score_sum.loc[0,'Param'] = param\n",
    "\n",
    "    #.sum() get the number of True    \n",
    "    score_sum.loc[0,'total_median'] = pre_results.loc[:,'Match_median'].sum()/len(pre_results)\n",
    "    score_sum.loc[0,'total_mean'] = pre_results.loc[:,'Match_mean'].sum()/len(pre_results)\n",
    "    score_sum.loc[0,'total_max'] = pre_results.loc[:,'Match_max'].sum()/len(pre_results)\n",
    "    #score_sum.loc[0,'total_min'] = pre_results.loc[:,'Match_min'].sum()/len(pre_results)\n",
    "\n",
    "    score_sum.loc[0,'NotChange_median'] =  pre_results.loc[NotChange_list,'Match_median'].sum()/len(NotChange_list)\n",
    "    score_sum.loc[0,'NotChange_mean'] =  pre_results.loc[NotChange_list,'Match_mean'].sum()/len(NotChange_list)\n",
    "    score_sum.loc[0,'NotChange_max'] =  pre_results.loc[NotChange_list,'Match_max'].sum()/len(NotChange_list)\n",
    "    #score_sum.loc[0,'NotChange_min'] =  pre_results.loc[NotChange_list,'Match_min'].sum()/len(NotChange_list)\n",
    "    \n",
    "    score_sum.loc[0,'MaybeChange_median'] =  pre_results.loc[MaybeChange_list,'Match_median'].sum()/len(MaybeChange_list)\n",
    "    score_sum.loc[0,'MaybeChange_mean'] =  pre_results.loc[MaybeChange_list,'Match_mean'].sum()/len(MaybeChange_list)\n",
    "    score_sum.loc[0,'MaybeChange_max'] =  pre_results.loc[MaybeChange_list,'Match_max'].sum()/len(MaybeChange_list)\n",
    "    #score_sum.loc[0,'MaybeChange_min'] =  pre_results.loc[MaybeChange_list,'Match_min'].sum()/len(MaybeChange_list)\n",
    "\n",
    "    score_sum.loc[0,'Change_median'] =  pre_results.loc[Change_list,'Match_median'].sum()/len(Change_list)\n",
    "    score_sum.loc[0,'Change_mean'] =  pre_results.loc[Change_list,'Match_mean'].sum()/len(Change_list)\n",
    "    score_sum.loc[0,'Change_max'] =  pre_results.loc[Change_list,'Match_max'].sum()/len(Change_list)\n",
    "    #score_sum.loc[0,'Change_min'] =  pre_results.loc[Change_list,'Match_min'].sum()/len(Change_list)\n",
    "\n",
    "    \n",
    "    import csv   \n",
    "    fields=list(score_sum.loc[0])\n",
    "    with open(savepath, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(fields)\n",
    "    \n",
    "    return(score_sum, pre_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_projection (adTr, adLn, key = 'org_cluster', mode = 'X', \n",
    "                      n_HVG = 100, n=50, frac=0.8, \n",
    "                      Ln_species = 'Patch', Tr_species = 'TenX',\n",
    "                      plot_tsne = False):\n",
    "# SCCAF projectin\n",
    "#input: adTr: training set; adLn, testing set;key, label for learning; mode, X or PCA or harmony PCA\n",
    "#output: dataframe of probablity of each cell, each label\n",
    "    \n",
    "    adTr_sub = data_subset(adTr)\n",
    "    TrLn = sele_dataset(adTr_sub, adLn, n_HVG = n_HVG,Ln_species = Ln_species, Tr_species = Tr_species)\n",
    "    print('get dataset')\n",
    "    \n",
    "    if mode == 'X':\n",
    "        Tr_sele = TrLn[TrLn.obs['source']==Tr_species,:]\n",
    "        Ln_sele = TrLn[TrLn.obs['source']==Ln_species,:]\n",
    "        Tr_matrix = Tr_sele.X\n",
    "        Ln_matrix = Ln_sele.X\n",
    "        print('split dataset')\n",
    "        \n",
    "    elif mode == 'X_pca':\n",
    "          \n",
    "\n",
    "        TrLn = run_PCA_Harmony(TrLn, run_Harmony = False, theta = 5,rep = 3)\n",
    "        Tr_sele = TrLn[TrLn.obs['source']==Tr_species,:]\n",
    "        Ln_sele = TrLn[TrLn.obs['source']==Ln_species,:]\n",
    "        \n",
    "        if scipy.sparse.issparse(adTr.obsm['X_pca']): \n",
    "            Tr_matrix  = Tr_sele.obsm['X_pca'].todense()\n",
    "        else:\n",
    "            Tr_matrix  = Tr_sele.obsm['X_pca']\n",
    "            \n",
    "        if scipy.sparse.issparse(adLn.obsm['X_pca']): \n",
    "            Ln_matrix  = Ln_sele.obsm['X_pca'].todense()\n",
    "        else:\n",
    "            Ln_matrix  = Ln_sele.obsm['X_pca']\n",
    "            \n",
    "        \n",
    "    elif mode == 'X_harmony':    \n",
    "        adTr_sub = data_subset(adTr)\n",
    "        TrLn = sele_dataset(adTr_sub, adLn, n_HVG = n_HVG,Ln_species = Ln_species, Tr_species = Tr_species)  \n",
    "        \n",
    "        TrLn = run_PCA_Harmony(TrLn, run_Harmony = True, theta = 5,rep = 4)\n",
    "        Tr_sele = TrLn[TrLn.obs['source']==Tr_species,:]\n",
    "        Ln_sele = TrLn[TrLn.obs['source']==Ln_species,:]\n",
    "        \n",
    "        if scipy.sparse.issparse(Tr_sele.obsm['X_harmony']): \n",
    "            Tr_matrix  = Tr_sele.obsm['X_harmony'].todense()\n",
    "        else:\n",
    "            Tr_matrix  = Tr_sele.obsm['X_harmony']\n",
    "            \n",
    "        if scipy.sparse.issparse(Ln_sele.obsm['X_harmony']): \n",
    "            Ln_matrix  = Ln_sele.obsm['X_harmony'].todense()\n",
    "        else:\n",
    "            Ln_matrix  = Ln_sele.obsm['X_harmony']\n",
    "        \n",
    "    print('split learning')    \n",
    "    X_train, X_test, y_train, y_test = train_test_split_per_type(Tr_matrix, Tr_sele.obs[key], n=n, frac=frac)\n",
    "    \n",
    "    print('regression')\n",
    "    clf = LogisticRegression(random_state=1, penalty='l1', C=0.5, solver = 'saga')\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if plot_tsne:\n",
    "        sc.pl.umap(adTr, color = [key])\n",
    "\n",
    "    Tr_sele.obs[key+'_predict'] = clf.predict(Tr_matrix)\n",
    "    if plot_tsne:\n",
    "        sc.pl.tsne(adTr, color = [key,key+'_predict'])\n",
    "    print('predicting')\n",
    "    adLn.obs[key + '_predict'] = clf.predict(Ln_matrix)\n",
    "    #sc.pl.tsne(adLn, color = [key,key+'_predict'])\n",
    "    df_prob = pd.DataFrame(clf.predict_proba(Ln_matrix),index = adLn.obs_names, columns = clf.classes_)\n",
    "    \n",
    "    return df_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87768bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 10X\n",
    "ad10x = sc.read('data/TenX_atlas.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f05ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_results\n",
    "sc.pl.umap(ad10x, color = 'org_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pre_processing\n",
    "figsize(4,4)\n",
    "ad10x.X = ad10x.layers['counts']\n",
    "sc.pp.normalize_per_cell(ad10x, counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(ad10x)\n",
    "ad10x.layers['raw'] = ad10x.X\n",
    "ad10x.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load patch-seq data\n",
    "adpatch = sc.read('data/retina_patch_all_qc.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch-seq data preprocessing\n",
    "figsize(4,4)\n",
    "adpatch.X = adpatch.layers['counts']\n",
    "sc.pp.normalize_per_cell(adpatch, counts_per_cell_after=1e5)\n",
    "sc.pp.log1p(adpatch)\n",
    "adpatch.layers['raw'] = adpatch.X\n",
    "adpatch.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe88902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check common genes\n",
    "common_genes = list((set(ad10x.var_names.tolist()))&(set(adpatch.var_names.tolist())))\n",
    "len(common_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use only the genes shared by the two datasets\n",
    "ad10x = ad10x[:,common_genes]\n",
    "ad10x\n",
    "adpatch = adpatch[:,common_genes]\n",
    "adpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping of SCCAF using different parameters\n",
    "\n",
    "n_gene_list  = [2000,4000,6000,8000,10000]\n",
    "mode_list = ['X','X_pca','X_harmony']\n",
    "tenx_cell_list = [25, 50, 75, 100,200,1000]\n",
    "N_rep_list =[1]\n",
    "penelty_list = ['l1','l2']\n",
    "C_value_list = [0.3,0.5,0.8]\n",
    "solver_mode_list = ['saga']\n",
    "\n",
    "\n",
    "for n_gene in n_gene_list:\n",
    "    for mode_use in mode_list:\n",
    "        for tenx_cell in tenx_cell_list:\n",
    "            for N_rep in N_rep_list:\n",
    "                for penelty in penelty_list:\n",
    "                    for C_value in C_value_list:\n",
    "                        for solver_mode in solver_mode_list:\n",
    "                            param = f'HVG_{n_gene}_{mode_use}_Tenx_{tenx_cell}_rep_{N_rep}_pen_{penelty}_C_{C_value}_solver_{solver_mode}'\n",
    "                            print(param)\n",
    "                            \n",
    "                            #skip calculated ones\n",
    "                            finished = pd.read_csv('data/score_summary.csv')\n",
    "                            if param in list(finished['Param']): \n",
    "                                    print('finished')\n",
    "                                    continue\n",
    "                            \n",
    "                            #load data\n",
    "                            ad10X, adpatch = load_h5(path_tenx = 'data/onc_atlas.h5', \n",
    "                                            path_patch = 'data/retina_patch_all_qc.h5' )\n",
    "                            \n",
    "                            #start of the function\n",
    "                            df_prob_rep = pd.Series()\n",
    "                            for rep in range(0, N_rep):\n",
    "                                print('repeat ' + str(rep))\n",
    "                                \n",
    "                                df_prob = pd.DataFrame()\n",
    "                                df_prob = label_projection(adTr = ad10x, adLn = adpatch,key = 'org_cluster',  Tr_species = 'TenX',Ln_species = 'Patch', \n",
    "                                                          mode = mode_use, n_HVG = n_gene, n=tenx_cell, frac=0.8,\n",
    "                                                           panelty = penelty, C_value = C_value, solver_mode = solver_mode,)\n",
    "                                df_prob_rep['rep_'+str(rep)] = df_prob\n",
    "                            \n",
    "                            #calucate score and write to csv\n",
    "                            score_sum, pre_results = find_save_score(df_prob_rep, manual_label, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3968e9f",
   "metadata": {},
   "source": [
    "# summary_all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_gene_list  = [2000,4000,6000,8000,10000]\n",
    "mode_list = ['X','X_pca','X_harmony']\n",
    "tenx_cell_list = [25, 50, 100,200,1000]\n",
    "N_rep_list =[1]\n",
    "penelty_list = ['l1','l2']\n",
    "C_value_list = [0.3,0.5,0.8]\n",
    "solver_mode_list = ['saga']\n",
    "\n",
    "\n",
    "para_list = []\n",
    "for n_gene in n_gene_list:\n",
    "    for mode_use in mode_list:\n",
    "        for tenx_cell in tenx_cell_list:\n",
    "            for N_rep in N_rep_list:\n",
    "                for penelty in penelty_list:\n",
    "                    for C_value in C_value_list:\n",
    "                        for solver_mode in solver_mode_list:\n",
    "                            param = f'HVG_{n_gene}_{mode_use}_Tenx_{tenx_cell}_rep_{N_rep}_pen_{penelty}_C_{C_value}_solver_{solver_mode}'\n",
    "                            print(param)\n",
    "                            para_list.append(param)\n",
    "len(para_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b47f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7143d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_all = pd.DataFrame(index = list(adpatch.obs_names))\n",
    "\n",
    "for para in para_list:\n",
    "    #print(para)\n",
    "    import pickle\n",
    "    with open(f'data/predict_results_all/{para}.pckl', 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "    df_pred_all[para] = x['rep_0'].idxmax(axis = 1)\n",
    "    \n",
    "df_pred_all.to_csv('results/df_predict_all_param.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_summary_all = pd.DataFrame(index = df_pred_tops.index)\n",
    "\n",
    "label_summary_all['best_fit'] = np.nan\n",
    "label_summary_all['best_fit_score'] = np.nan\n",
    "\n",
    "label_summary_all['2nd_fit'] = np.nan\n",
    "label_summary_all['2nd_fit_score'] = np.nan\n",
    "\n",
    "\n",
    "all_cells = df_pred_all.index.tolist()\n",
    "for cell in all_cells:\n",
    "    counts_info = df_pred_all.loc[cell,:].value_counts()\n",
    "    label_summary_all.loc[cell,'best_fit'] = counts_info.index.tolist()[0]\n",
    "    label_summary_all.loc[cell,'best_fit_score'] = counts_info[0]/sum(counts_info)\n",
    "    label_summary_all.loc[cell,'2nd_fit'] = counts_info.index.tolist()[(int(len(counts_info)>1))]\n",
    "    label_summary_all.loc[cell,'2nd_fit_score'] = counts_info[(int(len(counts_info)>1))]/sum(counts_info)\n",
    "label_summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44bc98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist(label_summary_all['best_fit_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_summary_all['best_fit_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b5b09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_summary_all['best_fit_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd1487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ec6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_summary_all.to_csv('data/SCCAF_projection_retina_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seurat4]",
   "language": "python",
   "name": "conda-env-seurat4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
